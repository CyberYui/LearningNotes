# AI绘画Stable Diffusion简易使用

> 一张AI绘图需要以下的步骤 : 搭建可复用环境 , 安装可复用模型 , 针对模型使用关键词 , 生成AI图片 , 穿帮修复

## 搭建环境,安装模型,关键词

搭建相关环境一般使用三种方式 :

1. 拉取GitHub源码部署 ( 可能有很多坑 )
2. 使用第三方本地整合包 ( 要求有超过3070的电脑, 此类方式要使用所有SD功能 )
3. 利用云上平台进行搭建

- 本次使用第三种方式, 在阿里云上进行相关搭建和使用

  > 只要从来没有用过函数计算或NAS存储, 即可参与阿里云试用

- 进入阿里云免费试用专场, 选择 **函数计算FC** 进行3个月的试用, 在工作台里, 创建应用

- 创建角色默认即可, 只是个称呼

- 进入应用菜单, 选择 **通过模板创建应用** , 这里不直接选择 SD , 而是选择人工智能里面的 **AI数字绘画stable-diffusion自定义模型版** , 部署类型选择直接部署 , 在此步先不要继续 , 先去领取NAS的免费试用 , 否则会产生别的费用 , NAS用来保存自定义模型

- 同样进入免费试用专栏 , 搜索NAS , 找到 **NAS存储** 点击试用 , 领取50GB的3个月试用

- 进入刚刚的函数计算控制台 , 授权角色 , 点一下直接授权刚刚创建的角色即可

- 下面的高级配置中, 地域选择杭州, 镜像地址直接复制下面示例说明中的地址即可, 部署成功后访问域名即可

  > 访问域名时, 需要使用外网下行流量, 这个只有在配置的时候要用, 保持钱包有钱即可

- 点击admin开头的进行相应的环境初始化 , 一路下一步即可 , 在最后的账号设置处设置好密码即可

- 登录后在可视化界面的地址栏处, 删掉个人空间这里的 `{source:5}` 字样 , 直接输入 `/mnt/auto/sd/` , 建议记住这个路径 , 这样之后就不需要再设置了

- 在此处展开models文件夹 , 点开 Stable-diffusion 文件夹 , 这里存放的就是我们的模型 , 大模型推荐使用 NeverEnding Dreams ( 即NED ) , 在 Stable-diffusion 同层级中可以找到 Lora 文件夹 , 这里存放小模型

  > mix4 和 20d 用来画妹子 , ss9 用来画帅哥

- 所有模型上传完毕之后 , 回到 函数计算FC 的应用菜单 , 点击打开访问域名中的另一个域名 , 即前端图形化操作界面

- 界面的左上角是大模型名称 , 可以通过下拉框选择 , 然后在下面选择 **文生图** 标签页, 上面的提示词即正相关词 , 下面的反向提示词即为负相关词 , 按照需求进行填写即可

- 右侧生成按钮下面有一个像印章(MP3)一样的小图标 , 点一下会出现一个选项卡弹出页面 , 这里我们选择 **低秩微调模型LoRA** 选项卡 , 这里点一个传好的小模型 , 比如 mix4 , 就会出现尖括号词组 , 如 `<lora:mix4:0.8>` 这里第一个参数即代表一个 LoRA , 第二个参数为模型名 , 注意模型名要填写模型的card上显示的完整名称 , 第三个参数为相关性 , 相关性是乘积关系 , 小于一是减少相关性 , 大于一是增加相关性 , 采样器选择 `DPM++ SDE Karras` , 采样步数为 40 , 勾选面部修复 , 生成种子不要选 -1 即可 , 生成完毕后勾选喜欢的图片 , 点击局部绘制 , 把生成的不喜欢的地方涂黑 , 然后微调下随机数 , 慢慢的就能生成自己喜欢的图片了

- 使用 LoRA 时 , 需要配合提示词 , 例如使用 mix4 就需要增加一个 mix4 提示词 , 即 `<lora:mix4:0.8>,mix4` 一般在 CivitAI 中 , 模型爱好者发布的 LoRA 信息中 , 其 Trigger Words 就是相关的提示词

- 这样就搭建好了一个简单的AI绘图模型了 , 可以自行炼丹了 , 如果要深入 , 则观看靠谱的轩轩的视频即可

- 分享作品时 , 分享内容为 : 图片 ; 正反关键词 ; 模型信息 ; 其他参数

- 如果自己不知道输入哪些关键词炼丹 , 那可以在 CivitAI 中找到喜欢的图片 , 下载好对应的模型 , 直接在别人的图片对应内容中复制 , 点击生成按钮左下角的小箭头生成图片

## 更简单的方法

- 网上相关UP有制作一键启动的傻瓜客户端 , 只要保证电脑上内存大于64GB , N系显卡 , 且显存>8GB , 就可以正常使用了 , 好一些的显卡 , 例如强于3080的 , 可以直接训练相关的AI模型

## 如何查询免费额度余额

- 进入阿里云 函数计算FC 控制台 , 找到概览 , 在右下角的资源包处可以看到相应的专项套餐剩余量 , 除去免费的部分 , 还有两个地方要收费 , 一个是磁盘使用费 ( 不是NAS中模型的费用 , 是SD的环境占用 , 一般为0.0063元/GB/小时 ) , 另一个是外网下行流量费用/公网出流量 ( 上传模型不收费, 但是下载计算的流量 , 一般为0.5/GB )

  > 我的阿里云余额已经用完了 , 阿里云的运行速率低于3060 , 且经常卡住 , 所以有条件尽量还是自己本地部署使用

## 相关的学习内容

- Stable Diffusion 在使用的时候 , 大模型 , 小模型 , 以及相关插件有很多 , 下面分别简单介绍一下

### 模型下载和分类

- 大模型 , 一般指大小超过2GB的模型 , 且文件后缀为 ckpt 或者 safetensors , 一般放在 `根目录\models/Stable-Diffusion` 文件夹下

  > 模型的下载可以有多种方法 , 可以找相关的大佬去要 , 也可以自己训练 , 一般都用下面两种方法下载
  >
  > 1. 可以在网上下载 , 比如C站 , 即 https://civitai.com 下载模型 , 这里的模型都有对应的预览图 , 要搜索大模型的话 , 勾选筛选里面的 `Checkpoint` 即可 , 需要注意该网站是要梯子才能进的 , 每个模型里面会有该模型的介绍以及对应的 Tags (即在网站中对应的标签) 和 Trigger Words (即触发该模型的关键词) , 每个大模型的介绍需要细看一下 , 里面一般会有作者推荐的运行参数
  >
  > 2. 如果使用的是傻瓜包 , 那就在模型管理下 , 这里下载模型是不需要科学上网的 , 找到 `Stable Diffusion模型` 选项卡 , 在此处下载即可 , 此处不同的选项卡区别见后文 , 这种方式唯一的问题就是没有预览图 , 像开盲盒一样
  >
  > [PS] 如果对别人生成的图片很好奇 , 可以点击对应图片右下角的 `!` 标志 , 可以看到对应的正负面词 , 但是具体用了那些额外插件就不知道了

- 在 C站 筛选模型的时候 , 可以看到有不同的 **Model types** , 比如 `Checkpoint` , 它们的意义和作用都不一样 , 简要介绍如下 :

  > - Checkpoint : 一般是大模型
  > - Textual Inversion : 
  > - Hypernetwork : 
  > - Aesthetic Gradient :
  > - LoRA : 
  > - LyCORIS : 
  > - Controlnet : 
  > - Poses :
  > - Wildcards : 
  > - Other : 

### SD操作界面相关

#### StableDiffusion模型

- 在最上面的 `Stable Diffusion 模型` 处即代表当前选择的大模型 , 如果实时更新了大模型 , 点击旁边对应的刷新按钮即可刷新你的大模型

#### VAE

- 第二个 `外挂VAE模型` , 即 Variational autoencoder , 变分自编码器 , 作用为滤镜+微调 , 其相关原理见后续内容

- 加载 VAE 后色彩的饱和度会更高 , 但是不同的 VAE 其饱和程度也不一样 , 比如下图所示 , 可以看到不同 VAE 作用下同一张图片的不同效果

  ![image-20230522211102150](./images/image-20230522211102150.png)

- 需要注意的是 , 有的大模型可能自带VAE , 如果再去添加VAE , 可能会直接影响整体出图效果 , 但是还是得多试才行

  > VAE后缀一般也是 ckpt , pt , safetensors , 其放置位置一般是 `根目录\models\VAE` 文件夹下
  >
  > 从C站基本上很难找到VAE , 我们一般使用傻瓜包里的模型管理去下载 , 即选择 `变分自编码器(VAE)模型` 标签来进行下载 , 同样的 , 不需要梯子即可正常下载

#### Embedding (Textual Inversion)

- Embedding , 又名 Textual Inversion , 即嵌入或文本反转 , 这里可以直接理解其为**打包的提示词** , 比如使用原版SD生成游戏角色 , 那需要特别多的tag去规定 , 但是如果引入了对应的 Embedding 后 , 那可以只引用例如 `dva` 这一个tag , 就实现了对应图片的生成

  > 由于说白了 Embedding 就是一堆 tag 的合集 , 故其大小按照一个txt文件看即可 , 后缀一般是 pt , 放置位置为 `根目录\embeddings` 文件夹
  >
  > Embedding 的下载还是在 C站 , 即筛选时将 `Model types` 选择为 `Textual Inversion` 即可

- Embedding 在界面中不会直接展示 , 使用时需要点击 ![image-20230522212747071](./images/image-20230522212747071.png) 按钮来展开对应内容 , 然后这里的 `嵌入式(T.I. Embedding)` 标签页中会显示对应的 embedding 插件 , 点击一个 , 即可将相应的关键词放入正相关 tag 中

#### LoRA

- LoRA , 全称 Low-Rank Adaptation of Large Language Models , 直译为大语言模型低阶适应 , 这是微软研究人员为解决大语言模型微调而开发的一项 AI 技术 , 其对应的技术实现原理见后续内容

- LoRA 最大的作用就是对人物和物品的复刻 , 即只要挂载了对应的 LoRA 模型 , 就可以基本 99% 地复刻出指定的人物特征 , 由于 LoRA 的定义很广泛 , 其实它可以实现画风 , 画面材质 , 特定人脸 , 固定人物动作 , 特定细节等等功能

- 通俗点来理解 , LoRA 几乎可以训练所有图片内容

  > LoRA 和 embedding 文件的作用看起来类似 , 但是其实 embedding 仅仅是一个 tags 的合集小模型文件 , 其能够通过定义 tags 实现出多视图等特定功能 , 而 LoRA 则是一种被训练过的特性提取模型 , 一般针对的是单一内容 , 但是深挖了细节
  >
  > 例如 : embedding 可以看成是简单的模仿 , 比如制作网站 , embedding 是做出了动态网页 , 由于网页量惊人 , 有相关的互动效果 , 但是实际上并没有动态数据库访问 , 只模仿到了形 , 而 LoRA 则是一个前后端整体框架完善的网站 , 抄到了精髓 , 故一般情况下 , 同样效果我们使用 LoRA 更多一些
  >
  > LoRA 也是在 C站 进行下载 , 即筛选时将 `Model types` 选择为 `LoRA` 即可 , 需要注意的是下载的时候一定不要用迅雷下载 , 会乱码且无法使用 , Lora 是一种小模型 , 一般放在 `根目录\models\Lora` 文件夹下

- LoRA 在使用时 , 需要首先确定好要使用的 LoRA 对应的大模型 , 至于某个 LoRA 究竟应该用哪个大模型去生成 , 需要在 C站 下载时打开对应的预览图信息 , 在此处查看 Model 项内容 , 即可找到对应 LoRA 的大模型

  > 大模型和 LoRA 并不是特定组合 , 只是不同的大模型针对同一个 LoRA 的生图效果可能不同

- LoRA 在界面中不会直接展示 , 使用时需要点击 ![image-20230522212747071](./images/image-20230522212747071.png) 按钮来展开对应内容 , 然后这里的 `lora` 标签页中会显示对应的 LoRA 模型 , 点击一个 , 即可将相应的LoRA 关键词放入正相关 tag 中 , 其形式一般为 `<lora:XX:1>` , 尖括号第一个参数即代表要使用 LoRA , 第二个参数是使用的 LoRA 的模型具体名称 , 第三个参数表示使用这个 LoRA 的比重 , 或者说是强度值 , 权重

  > LoRA 模型的一个很有意思的点是 , 其预览图和实际跑出来的图片可能会有买家秀和卖家秀一样的效果 , 即生成内容差距很大